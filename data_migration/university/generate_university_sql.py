import pandas as pd
import os
from datetime import datetime
import requests
import time
import json
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# íŒŒì¼ ê²½ë¡œ
file_path1 = "/Users/deokjoonkang/dev/projects/gundam/python/python-etc/data_migration/university/data/24ë…„ í•˜ë°˜ê¸° ëŒ€í•™ í•™êµë³„ ì¬ì  ì¬í•™ íœ´í•™ ì™¸êµ­ì¸ìœ í•™ìƒ êµì›_250109H.xlsx"
file_path2 = "/Users/deokjoonkang/dev/projects/gundam/python/python-etc/data_migration/university/data/í•™êµê°œí™©(20250507 ê¸°ì¤€).xls"

# SCHOOL í…Œì´ë¸” ì»¬ëŸ¼ëª…
SCHOOL_COLUMNS = [
    'TYPE', 'SIDO', 'NAME', 'CAMPUS', 'STATUS', 'OWNER',
    'POSTAL_CD', 'ADDRESS', 'TEL_NO', 'FAX_NO', 'URL', 'LATITUDE', 'LONGITUDE'
]

# ì¹´ì¹´ì˜¤ ë¡œì»¬ API ì„¤ì •
KAKAO_API_KEY = os.getenv('KAKAO_REST_API_KEY', '')
KAKAO_LOCAL_API_URL = "https://dapi.kakao.com/v2/local/search/address.json"

# ì£¼ì†Œë³„ ì¢Œí‘œ ìºì‹œ (ì¤‘ë³µ API í˜¸ì¶œ ë°©ì§€)
address_coordinates_cache = {}

def get_coordinates_from_address(address):
    """
    ì¹´ì¹´ì˜¤ ë¡œì»¬ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì†Œë¡œë¶€í„° ìœ„ë„, ê²½ë„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    ì¤‘ë³µ í˜¸ì¶œì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ìºì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Args:
        address (str): ì¡°íšŒí•  ì£¼ì†Œ
        
    Returns:
        tuple: (latitude, longitude) ë˜ëŠ” (0.0, 0.0) if ì‹¤íŒ¨
    """
    if not KAKAO_API_KEY:
        print("âš ï¸  ì¹´ì¹´ì˜¤ REST API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ KAKAO_REST_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return 0.0, 0.0
    
    if not address or address.strip() == '':
        return 0.0, 0.0
    
    # ìºì‹œì—ì„œ í™•ì¸
    clean_address = address.strip()
    if clean_address in address_coordinates_cache:
        lat, lng = address_coordinates_cache[clean_address]
        print(f"ğŸ“‹ ìºì‹œì—ì„œ ì¡°íšŒ: '{clean_address}' -> ì¢Œí‘œ: ({lat}, {lng})")
        return lat, lng
    
    try:
        headers = {
            'Authorization': f'KakaoAK {KAKAO_API_KEY}'
        }
        
        params = {
            'query': clean_address
        }
        
        response = requests.get(KAKAO_LOCAL_API_URL, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        
        if data['documents']:
            # ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš©
            first_result = data['documents'][0]
            latitude = float(first_result['y'])
            longitude = float(first_result['x'])
            print(f"ğŸ“ ì£¼ì†Œ '{clean_address}' -> ì¢Œí‘œ: ({latitude}, {longitude})")
            
            # ìºì‹œì— ì €ì¥
            address_coordinates_cache[clean_address] = (latitude, longitude)
            return latitude, longitude
        else:
            print(f"âŒ ì£¼ì†Œ '{clean_address}'ì— ëŒ€í•œ ì¢Œí‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            address_coordinates_cache[clean_address] = (0.0, 0.0)
            return 0.0, 0.0
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì£¼ì†Œ: {clean_address}): {str(e)}")
        address_coordinates_cache[clean_address] = (0.0, 0.0)
        return 0.0, 0.0
    except (KeyError, ValueError, json.JSONDecodeError) as e:
        print(f"âŒ API ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì£¼ì†Œ: {clean_address}): {str(e)}")
        address_coordinates_cache[clean_address] = (0.0, 0.0)
        return 0.0, 0.0

def update_coordinates_for_dataframe(df):
    """
    DataFrameì˜ ADDRESS ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ì—¬ ìœ„ë„, ê²½ë„ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    
    Args:
        df (DataFrame): ì—…ë°ì´íŠ¸í•  DataFrame
        
    Returns:
        DataFrame: ìœ„ë„, ê²½ë„ê°€ ì—…ë°ì´íŠ¸ëœ DataFrame
    """
    print(f"\nğŸ—ºï¸  ì´ {len(df)}ê°œ í•™êµì˜ ì£¼ì†Œì—ì„œ ì¢Œí‘œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤...")
    
    success_count = 0
    fail_count = 0
    cache_hit_count = 0
    
    for idx, row in df.iterrows():
        address = row['ADDRESS']
        if address and str(address).strip():
            clean_address = str(address).strip()
            
            # ìºì‹œ íˆíŠ¸ ì—¬ë¶€ í™•ì¸
            is_cache_hit = clean_address in address_coordinates_cache
            
            latitude, longitude = get_coordinates_from_address(address)
            df.at[idx, 'LATITUDE'] = latitude
            df.at[idx, 'LONGITUDE'] = longitude
            
            if latitude != 0.0 or longitude != 0.0:
                success_count += 1
            else:
                fail_count += 1
                
            if is_cache_hit:
                cache_hit_count += 1
            
            # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ë”œë ˆì´ (ìºì‹œ íˆíŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
            if not is_cache_hit:
                time.sleep(0.1)
        else:
            print(f"âš ï¸  ì¸ë±ìŠ¤ {idx}: ì£¼ì†Œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            fail_count += 1
    
    print(f"\nâœ… ì¢Œí‘œ ì¡°íšŒ ì™„ë£Œ:")
    print(f"   - ì„±ê³µ: {success_count}ê°œ")
    print(f"   - ì‹¤íŒ¨: {fail_count}ê°œ")
    print(f"   - ìºì‹œ íˆíŠ¸: {cache_hit_count}ê°œ")
    print(f"   - ì‹¤ì œ API í˜¸ì¶œ: {len(address_coordinates_cache)}ê°œ")
    
    return df

def clean_str(val):
    """ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì…ì„ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if pd.isna(val):
        return ''
    if val is None:
        return ''
    if isinstance(val, (int, float)):
        return str(val).strip()
    return str(val).replace("'", "''").strip()

def clean_campus(val):
    """CAMPUS í•„ë“œ ê°’ì„ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if pd.isna(val):
        return ''
    
    val_str = str(val).strip()
    
    # ë³¸êµ(ì œ1ìº í¼ìŠ¤) -> ë³¸êµ
    if val_str == 'ë³¸êµ(ì œ1ìº í¼ìŠ¤)':
        return 'ë³¸êµ'
    
    # ë³¸êµ(ì œ2ìº í¼ìŠ¤), ë³¸êµ(ì œ3ìº í¼ìŠ¤) ë“± -> ê´„í˜¸ ì•ˆì˜ í…ìŠ¤íŠ¸
    if val_str.startswith('ë³¸êµ(') and val_str.endswith(')'):
        return val_str[3:-1]  # 'ë³¸êµ(' ì œê±°í•˜ê³  ')' ì œê±°
    
    return val_str

def extract_from_first_file():
    # ì²« ë²ˆì§¸ íŒŒì¼ì€ 11ë²ˆì§¸ í–‰(ì¸ë±ìŠ¤ 10)ì´ ì‹¤ì œ í—¤ë”
    df = pd.read_excel(file_path1, header=10)
    # ì»¬ëŸ¼ëª…ì„ ëª¨ë‘ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ strip
    df.columns = [str(c).strip() for c in df.columns]
    print("ì²« ë²ˆì§¸ íŒŒì¼ ì‹¤ì œ ì»¬ëŸ¼ëª…:", list(df.columns))  # ë””ë²„ê¹…ìš©
    
    # ì²« ë²ˆì§¸ íŒŒì¼ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ê²Œ ë§¤í•‘
    col_map = {
        'í•™ì œ': 'TYPE',
        'ì‹œë„': 'SIDO',
        'í•™êµëª…': 'NAME',
        # 'ëŒ€í•™ì› êµ¬ë¶„\n(ë¶€ì„¤/\nëŒ€í•™ì›ëŒ€í•™)': 'CAMPUS',  # ë³¸ë¶„êµ ì •ë³´
        'ë³¸ë¶„êµ': 'CAMPUS',  # ë³¸ë¶„êµ ì •ë³´
        'í•™êµìƒíƒœ': 'STATUS',
        'ì„¤ë¦½': 'OWNER',
        'ìš°í¸ë²ˆí˜¸': 'POSTAL_CD',
        'ì£¼ì†Œ': 'ADDRESS',
        'ì „í™”ë²ˆí˜¸': 'TEL_NO',
        'íŒ©ìŠ¤ë²ˆí˜¸': 'FAX_NO',
        'í™ˆí˜ì´ì§€': 'URL',
    }
    
    # ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ ì²« ëª‡ í–‰ ì¶œë ¥
    print("ì²« ë²ˆì§¸ íŒŒì¼ ì²« 3í–‰ ë°ì´í„°:")
    print(df.head(3))
    
    # ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ë§¤í•‘
    use_cols = [c for c in col_map if c in df.columns]
    if use_cols:
        df = df[use_cols].rename(columns={k: v for k, v in col_map.items() if k in use_cols})
    
    # ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€
    for col in SCHOOL_COLUMNS:
        if col not in df.columns:
            df[col] = '' if col not in ['LATITUDE', 'LONGITUDE'] else 0.0
    
    df['LATITUDE'] = 0.0
    df['LONGITUDE'] = 0.0
    # CAMPUS í•„ë“œ ì •ë¦¬
    df['CAMPUS'] = df['CAMPUS'].apply(clean_campus)
    df = df.drop_duplicates(subset=['SIDO', 'NAME', 'CAMPUS'])
    
    # ìœ„ë„, ê²½ë„ ì¡°íšŒ
    df = update_coordinates_for_dataframe(df)
    
    return df[SCHOOL_COLUMNS]

def extract_from_second_file():
    df = pd.read_excel(file_path2, header=0)
    print("ë‘ ë²ˆì§¸ íŒŒì¼ ì‹¤ì œ ì»¬ëŸ¼ëª…:", list(df.columns))  # ë””ë²„ê¹…ìš©
    
    # ë‘ ë²ˆì§¸ íŒŒì¼ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ê²Œ ë§¤í•‘
    col_map = {
        'í•™ì œ': 'TYPE',
        'ì§€ì—­': 'SIDO',
        'í•™êµëª…': 'NAME',
        'ë³¸ë¶„êµ': 'CAMPUS',
        'í•™êµìƒíƒœ': 'STATUS',
        'ì„¤ë¦½êµ¬ë¶„': 'OWNER',
        'ìš°í¸ë²ˆí˜¸': 'POSTAL_CD',
        'ì£¼ì†Œ': 'ADDRESS',
        'í•™êµëŒ€í‘œ\r\në²ˆí˜¸': 'TEL_NO',
        'í•™êµëŒ€í‘œ\r\níŒ©ìŠ¤ë²ˆí˜¸': 'FAX_NO',
        'í•™êµí™ˆí˜ì´ì§€': 'URL',
    }
    
    # ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ ì²« ëª‡ í–‰ ì¶œë ¥
    print("ë‘ ë²ˆì§¸ íŒŒì¼ ì²« 3í–‰ ë°ì´í„°:")
    print(df.head(3))
    
    # ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ë§¤í•‘
    use_cols = [c for c in col_map if c in df.columns]
    if use_cols:
        df = df[use_cols].rename(columns={k: v for k, v in col_map.items() if k in use_cols})
    
    # ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€
    for col in SCHOOL_COLUMNS:
        if col not in df.columns:
            df[col] = '' if col not in ['LATITUDE', 'LONGITUDE'] else 0.0
    
    df['LATITUDE'] = 0.0
    df['LONGITUDE'] = 0.0
    # CAMPUS í•„ë“œ ì •ë¦¬
    df['CAMPUS'] = df['CAMPUS'].apply(clean_campus)
    df = df.drop_duplicates(subset=['SIDO', 'NAME', 'CAMPUS'])
    
    # ìœ„ë„, ê²½ë„ ì¡°íšŒ
    df = update_coordinates_for_dataframe(df)
    
    return df[SCHOOL_COLUMNS]

def merge_and_dedup(df1, df2):
    """
    ë‘ DataFrameì„ ë³‘í•©í•˜ê³  ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.
    ì²« ë²ˆì§¸ íŒŒì¼ì„ ìš°ì„ í•˜ë˜, ìœ„ë„/ê²½ë„ê°€ ì—†ìœ¼ë©´ ë‘ ë²ˆì§¸ íŒŒì¼ì—ì„œ ë³´ì™„í•©ë‹ˆë‹¤.
    
    Args:
        df1 (DataFrame): ì²« ë²ˆì§¸ íŒŒì¼ ë°ì´í„° (ìš°ì„ )
        df2 (DataFrame): ë‘ ë²ˆì§¸ íŒŒì¼ ë°ì´í„° (ë³´ì™„ìš©)
        
    Returns:
        DataFrame: ë³‘í•©ëœ ë°ì´í„°
    """
    print(f"\nğŸ”„ ë°ì´í„° ë³‘í•© ë° ì¤‘ë³µ ì œê±° ì‹œì‘...")
    print(f"   - ì²« ë²ˆì§¸ íŒŒì¼: {len(df1)}ê°œ")
    print(f"   - ë‘ ë²ˆì§¸ íŒŒì¼: {len(df2)}ê°œ")
    
    # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
    merged = df1.copy()
    
    # ë‘ ë²ˆì§¸ íŒŒì¼ì—ì„œ ë³´ì™„í•  ë°ì´í„° ì°¾ê¸°
    supplement_count = 0
    
    for idx1, row1 in merged.iterrows():
        # ìœ„ë„/ê²½ë„ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ë³´ì™„ ì‹œë„
        if (row1['LATITUDE'] == 0.0 and row1['LONGITUDE'] == 0.0) or \
           (pd.isna(row1['LATITUDE']) and pd.isna(row1['LONGITUDE'])):
            
            # ë‘ ë²ˆì§¸ íŒŒì¼ì—ì„œ ë™ì¼í•œ í•™êµ ì°¾ê¸°
            matching_rows = df2[
                (df2['SIDO'] == row1['SIDO']) & 
                (df2['NAME'] == row1['NAME']) & 
                (df2['CAMPUS'] == row1['CAMPUS'])
            ]
            
            if not matching_rows.empty:
                row2 = matching_rows.iloc[0]
                
                # ë‘ ë²ˆì§¸ íŒŒì¼ì— ìœ„ë„/ê²½ë„ê°€ ìˆìœ¼ë©´ ë³´ì™„
                if (row2['LATITUDE'] != 0.0 or row2['LONGITUDE'] != 0.0) and \
                   (not pd.isna(row2['LATITUDE']) and not pd.isna(row2['LONGITUDE'])):
                    
                    print(f"   ğŸ”„ ë³´ì™„: {row1['NAME']} ({row1['CAMPUS']}) - ìœ„ë„/ê²½ë„ ì¶”ê°€")
                    
                    # ìœ„ë„/ê²½ë„ ë³´ì™„
                    merged.at[idx1, 'LATITUDE'] = row2['LATITUDE']
                    merged.at[idx1, 'LONGITUDE'] = row2['LONGITUDE']
                    
                    # ì£¼ì†Œì™€ ìš°í¸ë²ˆí˜¸ë„ ë³´ì™„ (ì²« ë²ˆì§¸ íŒŒì¼ì— ì—†ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°)
                    if not row1['ADDRESS'] or str(row1['ADDRESS']).strip() == '':
                        merged.at[idx1, 'ADDRESS'] = row2['ADDRESS']
                        print(f"      ğŸ“ ì£¼ì†Œë„ ë³´ì™„: {row2['ADDRESS']}")
                    
                    if not row1['POSTAL_CD'] or str(row1['POSTAL_CD']).strip() == '':
                        merged.at[idx1, 'POSTAL_CD'] = row2['POSTAL_CD']
                        print(f"      ğŸ“® ìš°í¸ë²ˆí˜¸ë„ ë³´ì™„: {row2['POSTAL_CD']}")
                    
                    supplement_count += 1
    
    # ë‘ ë²ˆì§¸ íŒŒì¼ì—ì„œ ì²« ë²ˆì§¸ íŒŒì¼ì— ì—†ëŠ” í•™êµ ì¶”ê°€
    for idx2, row2 in df2.iterrows():
        # ì²« ë²ˆì§¸ íŒŒì¼ì— ì—†ëŠ” í•™êµì¸ì§€ í™•ì¸
        existing = merged[
            (merged['SIDO'] == row2['SIDO']) & 
            (merged['NAME'] == row2['NAME']) & 
            (merged['CAMPUS'] == row2['CAMPUS'])
        ]
        
        if existing.empty:
            merged = pd.concat([merged, pd.DataFrame([row2])], ignore_index=True)
            print(f"   â• ì¶”ê°€: {row2['NAME']} ({row2['CAMPUS']}) - ë‘ ë²ˆì§¸ íŒŒì¼ì—ì„œ")
    
    print(f"\nâœ… ë°ì´í„° ë³‘í•© ì™„ë£Œ:")
    print(f"   - ìµœì¢… ë°ì´í„°: {len(merged)}ê°œ")
    print(f"   - ìœ„ë„/ê²½ë„ ë³´ì™„: {supplement_count}ê°œ")
    
    return merged

def generate_school_insert_sql():
    df1 = extract_from_first_file()
    df2 = extract_from_second_file()
    df = merge_and_dedup(df1, df2)
    
    # ìºì‹œ í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š API í˜¸ì¶œ í†µê³„:")
    print(f"   - ê³ ìœ  ì£¼ì†Œ ìˆ˜: {len(address_coordinates_cache)}ê°œ")
    print(f"   - ìºì‹œëœ ì¢Œí‘œ ìˆ˜: {len([v for v in address_coordinates_cache.values() if v != (0.0, 0.0)])}ê°œ")
    print(f"   - ì‹¤íŒ¨í•œ ì£¼ì†Œ ìˆ˜: {len([v for v in address_coordinates_cache.values() if v == (0.0, 0.0)])}ê°œ")
    
    output_file = "/Users/deokjoonkang/dev/projects/gundam/python/python-etc/data_migration/university/output/school_insert.sql"
    # ë””ë ‰í† ë¦¬ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("-- SCHOOL í…Œì´ë¸” INSERT SQL\n")
        f.write(f"-- ìƒì„±ì¼ì‹œ: {current_time}\n")
        f.write(f"-- ì´ {len(df)}ê°œ í•™êµ ë°ì´í„°\n\n")
        f.write("INSERT INTO SCHOOL (TYPE, SIDO, NAME, CAMPUS, STATUS, OWNER, POSTAL_CD, ADDRESS, TEL_NO, FAX_NO, URL, LATITUDE, LONGITUDE) VALUES\n")
        sql_values = []
        for _, row in df.iterrows():
            values = [
                f"'{clean_str(row['TYPE'])}'",
                f"'{clean_str(row['SIDO'])}'",
                f"'{clean_str(row['NAME'])}'",
                f"'{clean_str(row['CAMPUS'])}'",
                f"'{clean_str(row['STATUS'])}'",
                f"'{clean_str(row['OWNER'])}'",
                f"'{clean_str(row['POSTAL_CD'])}'",
                f"'{clean_str(row['ADDRESS'])}'",
                f"'{clean_str(row['TEL_NO'])}'",
                f"'{clean_str(row['FAX_NO'])}'",
                f"'{clean_str(row['URL'])}'",
                f"{row['LATITUDE']}",
                f"{row['LONGITUDE']}"
            ]
            sql_values.append(f"({', '.join(values)})")
        for i, sql_value in enumerate(sql_values):
            if i == len(sql_values) - 1:
                f.write(sql_value + ";\n")
            else:
                f.write(sql_value + ",\n")
        f.write(f"\n-- ì´ {len(sql_values)}ê°œì˜ INSERT ë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
        f.write(f"-- ìƒì„± ì™„ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    print(f"\nâœ… SQL íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ“ íŒŒì¼ëª…: {output_file}")
    print(f"ğŸ“Š ì´ {len(sql_values)}ê°œì˜ INSERT ë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return output_file

def preview_sql_file(filename, lines=10):
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            content = f.readlines()
        print(f"\nğŸ“‹ SQL íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ {lines}ì¤„):")
        print("=" * 60)
        for i, line in enumerate(content[:lines]):
            print(f"{i+1:2d}: {line.rstrip()}")
        if len(content) > lines:
            print("...")
            print(f"ì´ {len(content)}ì¤„")
    except Exception as e:
        print(f"íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    sql_file = generate_school_insert_sql()
    if sql_file:
        preview_sql_file(sql_file, 15)
        print(f"\nğŸ‰ SCHOOL í…Œì´ë¸” INSERT SQL ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ’¡ ìƒì„±ëœ íŒŒì¼ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        print("âŒ SQL íŒŒì¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
