import pandas as pd
import os
from datetime import datetime

# íŒŒì¼ ê²½ë¡œ
file_path1 = "/Users/deokjoonkang/dev/projects/gundam/python/python-etc/data_migration/university/data/24ë…„ í•˜ë°˜ê¸° ëŒ€í•™ í•™êµë³„ ì¬ì  ì¬í•™ íœ´í•™ ì™¸êµ­ì¸ìœ í•™ìƒ êµì›_250109H.xlsx"
file_path2 = "/Users/deokjoonkang/dev/projects/gundam/python/python-etc/data_migration/university/data/í•™êµê°œí™©(20250507 ê¸°ì¤€).xls"

# SCHOOL í…Œì´ë¸” ì»¬ëŸ¼ëª…
SCHOOL_COLUMNS = [
    'TYPE', 'SIDO', 'NAME', 'CAMPUS', 'STATUS', 'OWNER',
    'POSTAL_CD', 'ADDRESS', 'TEL_NO', 'FAX_NO', 'URL', 'LATITUDE', 'LONGITUDE'
]

def clean_str(val):
    if pd.isna(val):
        return ''
    return str(val).replace("'", "''").strip()

def extract_from_first_file():
    df = pd.read_excel(file_path1, header=11)
    # ì»¬ëŸ¼ëª…ì„ ëª¨ë‘ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ strip
    df.columns = [str(c).strip() for c in df.columns]
    print("ì‹¤ì œ ì»¬ëŸ¼ëª…:", list(df.columns))  # ë””ë²„ê¹…ìš©
    col_map = {
        'í•™ì œ': 'TYPE',
        'ì‹œë„': 'SIDO',
        'í•™êµëª…': 'NAME',
        'ë³¸ë¶„êµ': 'CAMPUS',
        'í•™êµìƒíƒœ': 'STATUS',
        'ì„¤ë¦½': 'OWNER',
        'ìš°í¸ë²ˆí˜¸': 'POSTAL_CD',
        'ì£¼ì†Œ': 'ADDRESS',
        'ì „í™”ë²ˆí˜¸': 'TEL_NO',
        'íŒ©ìŠ¤ë²ˆí˜¸': 'FAX_NO',
        'í™ˆí˜ì´ì§€': 'URL',
    }
    use_cols = [c for c in col_map if c in df.columns]
    df = df[use_cols].rename(columns={k: v for k, v in col_map.items() if k in use_cols})
    for col in SCHOOL_COLUMNS:
        if col not in df.columns:
            df[col] = '' if col not in ['LATITUDE', 'LONGITUDE'] else 0.0
    df['LATITUDE'] = 0.0
    df['LONGITUDE'] = 0.0
    df = df.drop_duplicates(subset=['NAME', 'CAMPUS'])
    return df[SCHOOL_COLUMNS]

def extract_from_second_file():
    df = pd.read_excel(file_path2, header=0)
    # ì»¬ëŸ¼ëª… ë§¤í•‘ (ìº¡ì²˜ ì°¸ê³ , ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ê²Œ ì¡°ì •)
    col_map = {
        'í•™ì œ': 'TYPE',
        'ì‹œë„': 'SIDO',
        'í•™êµëª…': 'NAME',
        'ë³¸ë¶„êµ': 'CAMPUS',
        'í•™êµìƒíƒœ': 'STATUS',
        'ì„¤ë¦½': 'OWNER',
        'ìš°í¸ë²ˆí˜¸': 'POSTAL_CD',
        'ì£¼ì†Œ': 'ADDRESS',
        'ì „í™”ë²ˆí˜¸': 'TEL_NO',
        'íŒ©ìŠ¤ë²ˆí˜¸': 'FAX_NO',
        'í™ˆí˜ì´ì§€': 'URL',
    }
    df = df[[c for c in col_map if c in df.columns]].rename(columns=col_map)
    for col in SCHOOL_COLUMNS:
        if col not in df.columns:
            df[col] = '' if col not in ['LATITUDE', 'LONGITUDE'] else 0.0
    df['LATITUDE'] = 0.0
    df['LONGITUDE'] = 0.0
    df = df.drop_duplicates(subset=['NAME', 'CAMPUS'])
    return df[SCHOOL_COLUMNS]

def merge_and_dedup(df1, df2):
    # ì²« ë²ˆì§¸ íŒŒì¼ì— ì—†ëŠ” (í•™êµëª…+ìº í¼ìŠ¤)ë§Œ ë‘ ë²ˆì§¸ íŒŒì¼ì—ì„œ ì¶”ê°€
    merged = pd.concat([df1, df2], ignore_index=True)
    merged = merged.drop_duplicates(subset=['NAME', 'CAMPUS'], keep='first')
    return merged

def generate_school_insert_sql():
    df1 = extract_from_first_file()
    df2 = extract_from_second_file()
    df = merge_and_dedup(df1, df2)
    output_file = "/Users/deokjoonkang/dev/projects/gundam/python/python-etc/data_migration/university/output/school_insert.sql"
    # ë””ë ‰í† ë¦¬ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("-- SCHOOL í…Œì´ë¸” INSERT SQL\n")
        f.write(f"-- ìƒì„±ì¼ì‹œ: {current_time}\n")
        f.write(f"-- ì´ {len(df)}ê°œ í•™êµ ë°ì´í„°\n\n")
        f.write("INSERT INTO SCHOOL (TYPE, SIDO, NAME, CAMPUS, STATUS, OWNER, POSTAL_CD, ADDRESS, TEL_NO, FAX_NO, URL, LATITUDE, LONGITUDE) VALUES\n")
        sql_values = []
        for _, row in df.iterrows():
            values = [
                f"'{clean_str(row['TYPE'])}'",
                f"'{clean_str(row['SIDO'])}'",
                f"'{clean_str(row['NAME'])}'",
                f"'{clean_str(row['CAMPUS'])}'",
                f"'{clean_str(row['STATUS'])}'",
                f"'{clean_str(row['OWNER'])}'",
                f"'{clean_str(row['POSTAL_CD'])}'",
                f"'{clean_str(row['ADDRESS'])}'",
                f"'{clean_str(row['TEL_NO'])}'",
                f"'{clean_str(row['FAX_NO'])}'",
                f"'{clean_str(row['URL'])}'",
                f"{row['LATITUDE']}",
                f"{row['LONGITUDE']}"
            ]
            sql_values.append(f"({', '.join(values)})")
        for i, sql_value in enumerate(sql_values):
            if i == len(sql_values) - 1:
                f.write(sql_value + ";\n")
            else:
                f.write(sql_value + ",\n")
        f.write(f"\n-- ì´ {len(sql_values)}ê°œì˜ INSERT ë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
        f.write(f"-- ìƒì„± ì™„ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    print(f"\nâœ… SQL íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ“ íŒŒì¼ëª…: {output_file}")
    print(f"ğŸ“Š ì´ {len(sql_values)}ê°œì˜ INSERT ë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return output_file

def preview_sql_file(filename, lines=10):
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            content = f.readlines()
        print(f"\nğŸ“‹ SQL íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ {lines}ì¤„):")
        print("=" * 60)
        for i, line in enumerate(content[:lines]):
            print(f"{i+1:2d}: {line.rstrip()}")
        if len(content) > lines:
            print("...")
            print(f"ì´ {len(content)}ì¤„")
    except Exception as e:
        print(f"íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    sql_file = generate_school_insert_sql()
    if sql_file:
        preview_sql_file(sql_file, 15)
        print(f"\nğŸ‰ SCHOOL í…Œì´ë¸” INSERT SQL ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ’¡ ìƒì„±ëœ íŒŒì¼ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        print("âŒ SQL íŒŒì¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
